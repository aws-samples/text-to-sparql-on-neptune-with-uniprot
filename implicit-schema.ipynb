{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f15ec2-955c-49f0-b671-24869d287c0b",
   "metadata": {},
   "source": [
    "# SPARQL generation via implicit schema representation and Generative AI\n",
    "---\n",
    "This notebook demonstrates one way to generate SPARQL queries from natural language questions. Here we focus on\n",
    "prompting the model by showing the model examples of SPARQL queries (and their associated natural language questions)\n",
    "and relying on the LLM to infer the graph schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d689b-bab5-4e98-b8fa-0b0e1822e631",
   "metadata": {},
   "source": [
    "If you are running this notebook outside of an AWS environment (e.g., on your laptop) then you will need\n",
    "to set up your AWS credentials in ~/.aws/credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d1e15-d743-4e5d-a1b0-26309fcb7b67",
   "metadata": {},
   "source": [
    "If you are running this notebook inside of an AWS environment (e.g., inside Sagemaker Studio or as a Neptune notebook) then\n",
    "use the \"conda_pytorch_p310\" kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf7eee-acf3-43bb-9d32-8480a9d8d7d4",
   "metadata": {},
   "source": [
    "To access the Bedrock API from this notebook the notebook's execution role must have a policy to allow Bedrock access.\n",
    "To find this notebook's execution role run the following code in this notebook:\n",
    "```\n",
    "print(sagemaker.get_execution_role())\n",
    "```\n",
    "and then go to the IAM console and add the policy `AmazonBedrockFullAccess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "968f025f-44f4-4d8d-aacc-f453fde4e5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The first time you run this notebook you'll need to uncomment these lines\n",
    "# to install the required Python dependencies:\n",
    "# %pip install -q boto3==1.34.*\n",
    "# %pip install -q botocore==1.34.*\n",
    "# %pip install -q jupyter==1.0.*\n",
    "# %pip install -q sagemaker==2.212.*\n",
    "# %pip install -q jinja2==3.1.*\n",
    "# %pip install -q ipykernel==6.29.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77447818-202f-478a-b8ce-1560246e30d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -qU anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7abefcaf-bd69-4ca6-a094-55220fba33f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "from typing import Any as JsonType\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "from functools import partial\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "import utilities as u\n",
    "# To reload utilities.py without restarting the notebook kernel use the following:\n",
    "# importlib.reload(u)\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5631881-6891-4534-9c11-c85acfa1a89e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ANTHROPIC_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env ANTHROPIC_API_KEY=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f6822692-d11b-4da6-a4e7-fde8ca8b3041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "def opus_llm(prompt_json) -> str:\n",
    "    if \"system\" in prompt_json[0]:\n",
    "        kwargs = {\"system\": prompt_json[0][\"system\"]}\n",
    "        prompt_json = prompt_json[1:]\n",
    "    else:\n",
    "        kwargs = {}\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=1024,\n",
    "        messages=prompt_json,\n",
    "        **kwargs)\n",
    "    print(f\"response message: {message}\")\n",
    "    result = \"\".join(block.text for block in message.content)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21508a91",
   "metadata": {},
   "source": [
    "## Set Neptune and Bedrock clients\n",
    "\n",
    "### Get connection to Neptune database\n",
    "And define a function to run a SPARQL query on that database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b29fa6",
   "metadata": {},
   "source": [
    "### Setup Bedrock client\n",
    "And specify which model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7712ca71-5768-4d7e-acf1-bcfb94c573e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "# bedrock = boto3.client(\"bedrock\", region_name=region)\n",
    "jenv = jinja2.Environment(trim_blocks=True, lstrip_blocks=True)\n",
    "\n",
    "model_id = \"anthropic.claude-v2:1\"\n",
    "# model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "temperature = 0.3\n",
    "\n",
    "resources = Path.cwd() / \"resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94163080-4405-4ce0-b93c-e24983057414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(u)\n",
    "llm = u.create_bedrock_runner(bedrock_runtime,\n",
    "                              model_id,\n",
    "                              temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3221dc24-ed7d-497d-b859-8e9942bfc7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conversions = [(\"\\\"\", r'\\\"'),\n",
    "#                (\"\\\\\", r\"\\\\\"),\n",
    "#                (\"/\",  r\"\\/\"),\n",
    "#                (\"\\b\", r\"\\f\"),\n",
    "#                (\"\\f\", r\"\\f\"),\n",
    "#                (\"\\n\", r\"\\n\"),\n",
    "#                (\"\\r\", r\"\\r\"),\n",
    "#                (\"\\t\", r\"\\t\")]\n",
    "\n",
    "# def escape_literal_string_for_json(input: Union[str, list, dict]) -> Union[str, list, dict]:\n",
    "#     if isinstance(input, str):\n",
    "#         for in_s, out_s in conversions:\n",
    "#             input = input.replace(in_s, out_s)\n",
    "#         return input\n",
    "#     elif isinstance(input, list):\n",
    "#         return list(map(escape_literal_string_for_json, input))\n",
    "#     else:\n",
    "#         return {k: escape_literal_string_for_json(v) for k, v in input.items()}\n",
    "\n",
    "# print(escape_literal_string_for_json(\"foo\\nbar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8246fcb-f7c9-41b3-a66a-b4e23e3fa256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template_json = yaml.safe_load((resources / \"prompt.yaml\").read_text())\n",
    "\n",
    "\n",
    "def apply_jinja(json_blob: JsonType, **kwargs) -> JsonType:\n",
    "    if isinstance(json_blob, str):\n",
    "        return jenv.from_string(json_blob).render(\n",
    "                        question=kwargs[\"question\"],\n",
    "                        tips=kwargs[\"tips\"],\n",
    "                        examples=kwargs[\"examples\"])\n",
    "    elif isinstance(json_blob, list):\n",
    "        return [apply_jinja(x, **kwargs) for x in json_blob]\n",
    "    elif isinstance(json_blob, dict):\n",
    "        return {k: apply_jinja(v, **kwargs) for k, v in json_blob.items()}\n",
    "    else:\n",
    "        return json_blob\n",
    "\n",
    "\n",
    "def generate_prompt(prompt_template_json: JsonType,\n",
    "                    tips: List[str],\n",
    "                    question: str,\n",
    "                    few_shot_examples: List[dict]) -> JsonType:\n",
    "    # print(f\"gen prompt {type(prompt_json_str)} <<{prompt_json_str}>>\")\n",
    "    prompt_json = apply_jinja(prompt_template_json, \n",
    "                               question=question,\n",
    "                               tips=tips,\n",
    "                               examples=few_shot_examples)\n",
    "    # print(f\"prompt: <<{prompt}>>\")\n",
    "    return prompt_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "672b530f-37d4-41c7-8153-3922996e5166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'system': 'You are an expert-level onotologist who is knowledgeable of SPARQL and the Uniprot schema.'}, {'role': 'user', 'content': \"Your task is to convert an English language description of a question into a SPARQL query against the Uniprot\\nknowledgebase that answers the question. You must include your answer in a <sparql></sparql> tag pair. You don't\\nneed to add the PREFIX lines, I'll add those.\\n\\n{% if examples is defined and examples|length > 0 %}\\nSome examples:\\n\\n{% for example in examples %}\\n<question>\\n  {{ example.question }} \\n</question>\\n\\n<sparql>\\n{{ example.SPARQL }}\\n</sparql>\\n\\n{% endfor %}\\n{% endif %}\\n\\n{% if tips is defined and tips|length > 0 %}\\n\\nHere are some additional tips that you'll find helpful:\\n\\n<tips>\\n{% for tip in tips %}\\n<tip>{{ tip }}</tip>\\n{% endfor %}\\n<tips>\\n{% endif %}\\n\\nYou can use the following keywords:\\n\\n<keywords>\\n  <keyword><ARN>keywords:5</ARN><name>Acetoin biosynthesis</name></keyword>\\n  <keyword><ARN>keywords:47</ARN><name>Antifreeze protein</name></keyword>\\n</keywords>\\n\\nNow, it's your turn! Please convert the following question into a SPARQL query against the Uniprot knowledgebase that answers the question.\\n\\nYou must wrap your answer in <sparql></sparql> tags.\\n\\n<question>\\n{{question}}\\n</question>\"}, {'role': 'assistant', 'content': '<sparql>'}]\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e642d",
   "metadata": {},
   "source": [
    "### Define functions to generate SPARQL using LLM via Bedrock and run it against Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9067b9e4-663a-4aaa-817f-457da0ba9180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sparql(llm, prompt_template: JsonType,\n",
    "                    tips: List[str],\n",
    "                    question: str,\n",
    "                    few_shot_examples: List[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Given a natural language question, use the LLM to transform that\n",
    "    into a SPARQL query (using the prompt template) and return the query.\n",
    "    \"\"\"\n",
    "    prompt = generate_prompt(prompt_template, tips, question, few_shot_examples)\n",
    "    # print(f\"prompt:\")\n",
    "    # for x in prompt:\n",
    "    #     print(f\" > {x}\")\n",
    "    response = llm(prompt)\n",
    "    # print(f\"response: <<<{response}>>>\")\n",
    "    try:\n",
    "        idx = response.index(\"<sparql>\")\n",
    "        response = response[idx+8:]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        idx = response.index(\"</sparql>\")\n",
    "        response = response[:idx]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return response\n",
    "\n",
    "\n",
    "generate_and_run = partial(u.generate_and_run,\n",
    "                           sparql_generator=generate_sparql,\n",
    "                           sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8aa5f8cb-324e-4800-bb05-bd01942b3827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth = yaml.safe_load((resources / \"ground-truth.yaml\").read_text())\n",
    "tips = yaml.safe_load((resources / \"tips.yaml\").read_text())\n",
    "\n",
    "\n",
    "def evaluate_model(llm, prompt_template: JsonType, tips: List[str],\n",
    "                   override_range: Optional[range]=None):\n",
    "    num_exact_matches = 0\n",
    "    for idx in override_range or range(len(ground_truth)):\n",
    "        hold_out = ground_truth[idx]\n",
    "        training_examples = ground_truth[:idx] + ground_truth[idx+1:]\n",
    "        assert hold_out[\"SPARQL\"] not in {x[\"SPARQL\"] for x in training_examples}\n",
    "        print(f\"#{idx:,}: {hold_out['question']}\")\n",
    "        sparql = generate_sparql(llm, prompt_template, tips, \n",
    "                                 hold_out[\"question\"], training_examples)\n",
    "        print()\n",
    "        print(f\">Generated:\\n{sparql.strip()}\\n\")\n",
    "        print(f\">Ground truth:\\n{hold_out['SPARQL'].strip()}\")\n",
    "        print()\n",
    "        if u.normalize_ws(sparql) == u.normalize_ws(hold_out['SPARQL']):\n",
    "            num_exact_matches += 1\n",
    "    print(f\"Based on {len(ground_truth):,} examples, {(num_exact_matches/len(ground_truth))*100.0}% correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "07822deb-5b31-472b-a34f-803be2cc150a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#35: Use UniProt clusters to find the similar proteins for UniProtKB entry P05067 and then sort them by UniRef cluster identity\n",
      "response message: Message(id='msg_01Fo7hRDkqKG7QRDVAt2CN4b', content=[TextBlock(text='\\nSELECT \\n  ?protein  \\n  ?prot ?identity \\nWHERE {\\n  ?cluster a up:UniRef100Cluster ;\\n      up:member uniprotkb:P05067 ;\\n      up:member ?protein . \\n\\n  ?protein a up:Protein ;\\n      up:sequenceFor ?prot .\\n\\n  ?cluster up:sequence ?clusterSequence .\\n\\n  SERVICE <https://sparql.uniprot.org/sparql>\\n  {\\n     SELECT \\n       (round(100.0*(xsd:float(?length)/str(?n))) as ?identity)\\n     {\\n       SELECT (count(*) AS ?length) {\\n         ?clusterSequence rdf:value ?seq .\\n         ?prot rdf:value ?seq .\\n       }\\n       SELECT (strlen(str(?clusterSequence)) AS ?n) {\\n         ?clusterSequence rdf:value ?seq .\\n       }\\n     }\\n  }\\n} ORDER BY DESC(?identity)\\n</sparql>\\n\\nThe key steps are:\\n\\n1. Find the UniRef100 cluster that P05067 belongs to using up:member. This cluster will contain similar proteins.\\n\\n2. Get the proteins in that cluster, and for each protein get the ?prot which is the UniParc sequence using up:sequenceFor. \\n\\n3. Get the cluster sequence using up:sequence on the cluster.\\n\\n4. Use a subquery to calculate the identity between the cluster sequence and each protein sequence:\\n   - Get the length of the cluster sequence \\n   - For each protein, count how many residues match the cluster sequence\\n   - Calculate the percentage identity by dividing the match count by the cluster sequence length\\n\\n5. Order the results by descending identity percentage to sort the most similar proteins first.\\n\\nThe key predicates used are up:member to find cluster contents, up:sequenceFor to link proteins to UniParc sequences, and up:sequence to get the cluster sequence. The identity calculation uses basic SPARQL 1.1 aggregates and arithmetic.', type='text')], model='claude-3-opus-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=13820, output_tokens=466))\n",
      "\n",
      ">Generated:\n",
      "SELECT \n",
      "  ?protein  \n",
      "  ?prot ?identity \n",
      "WHERE {\n",
      "  ?cluster a up:UniRef100Cluster ;\n",
      "      up:member uniprotkb:P05067 ;\n",
      "      up:member ?protein . \n",
      "\n",
      "  ?protein a up:Protein ;\n",
      "      up:sequenceFor ?prot .\n",
      "\n",
      "  ?cluster up:sequence ?clusterSequence .\n",
      "\n",
      "  SERVICE <https://sparql.uniprot.org/sparql>\n",
      "  {\n",
      "     SELECT \n",
      "       (round(100.0*(xsd:float(?length)/str(?n))) as ?identity)\n",
      "     {\n",
      "       SELECT (count(*) AS ?length) {\n",
      "         ?clusterSequence rdf:value ?seq .\n",
      "         ?prot rdf:value ?seq .\n",
      "       }\n",
      "       SELECT (strlen(str(?clusterSequence)) AS ?n) {\n",
      "         ?clusterSequence rdf:value ?seq .\n",
      "       }\n",
      "     }\n",
      "  }\n",
      "} ORDER BY DESC(?identity)\n",
      "\n",
      ">Ground truth:\n",
      "SELECT \n",
      "    ?similar ?identity\n",
      "FROM <http://sparql.uniprot.org/uniref>\n",
      "FROM <http://sparql.uniprot.org/uniprot>\n",
      "WHERE\n",
      "{\n",
      "    BIND (uniprotkb:P05607 AS ?protein)\n",
      "    ?cluster up:member ?member ;\n",
      "             up:member/up:sequenceFor ?protein;\n",
      "             up:identity ?identity .\n",
      "    ?member up:sequenceFor ?similar .\n",
      "    FILTER(!sameTerm(?similar, ?protein))\n",
      "} \n",
      "ORDER BY DESC(?identity)\n",
      "\n",
      "Based on 60 examples, 0.0% correct\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(opus_llm, prompt_template_json, tips, override_range=range(35, 36))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9d2c0",
   "metadata": {},
   "source": [
    "## Try some queries\n",
    "\n",
    "Here are some example queries that you can try. These queries are the same as those used for the few-shot prompting so they\n",
    "are not a good guide to the model's ability to generalize beyond those examples. However, you can use these as a starting\n",
    "point to explore the ability of the model to generate de novo SPARQL queries.\n",
    "\n",
    "- What GO terms are associated with human proteins?\n",
    "- What GO terms are associated with human proteins? Show me their names also.\n",
    "- How many citations are there for papers by A. Bairoch?\n",
    "- Show me all citations by A. Bairoch\n",
    "- Show me all proteins that are located in the mitochondrian\n",
    "- I'd like to see the entries for all proteins encoded by the gene FNDC3A\n",
    "- Select all taxa from the UniProt taxonomy\n",
    "- Select all taxa from the UniProt taxonomy; show me at most 7\n",
    "- Show me at most 5 taxa from the UniProt taxonomy\n",
    "- Select all bacterial taxa and their scientific names from the UniProt taxonomy\n",
    "- Show me up to 10 human taxa and their scientific names from the UniProt taxonomy\n",
    "- Select up to 10 bacterial taxa and their scientific names from the UniProt taxonomy\n",
    "- Tell me all the different categories of databases\n",
    "- Tell me all the different databases you know about\n",
    "- Select all UniProt entries, and their organism and amino acid sequences (including isoforms), for _E. coli K12_ and all its strains\n",
    "- Select the UniProt entry with the mnemonic 'A4_HUMAN'\n",
    "- Select a mapping of UniProt to PDB entries using the UniProt cross-references to the PDB database\n",
    "- Select all cross-references to external databases of the category '3D structure databases' of UniProt entries that are classified with the keyword 'Acetoin biosynthesis (KW-0005)'\n",
    "- Select reviewed UniProt entries (Swiss-Prot), and their recommended protein name, that have a preferred gene name that contains the text 'DNA'\n",
    "- Select reviewed UniProt entries (Swiss-Prot), and their recommended protein name, that have a preferred gene name that contains the word DNA. Show me the gene name too\n",
    "- Show me the preferred gene name and disease annotation of all human UniProt entries that are known to be involved in a disease\n",
    "- Select all human UniProt entries with a sequence variant that leads to a 'loss of function'\n",
    "- Select all distinct human UniProt entries with a sequence variant that leads to a 'loss of function', show me the text of the annotation also\n",
    "- Show me all human UniProt entries with a sequence variant that leads to a tyrosine to phenylalanine substitution\n",
    "- Show me all human UniProt entries with a sequence variant that leads to a Tyr to phenylalanine substitution\n",
    "- Select all UniProt entries with annotated transmembrane regions and the regions' begin and end coordinates on the canonical sequence\n",
    "- Select all UniProt entries that were integrated on the 30th of November 2010\n",
    "- Select all UniProt entries that were integrated on or before the 30th of November 2010\n",
    "- Select all UniProt entries that were integrated on the month of November 2010\n",
    "- Show me all UniProt entries that were added to the database on the month of November 2010\n",
    "- Select the average number of cross-references to the PDB database of UniProt entries that have at least one cross-reference to the PDB database\n",
    "- Select the number of UniProt entries for each of the EC (Enzyme Commission) second level categories\n",
    "- Find all Natural Variant Annotations if associated via an evidence tag to an article with a pubmed identifier.\n",
    "- Find where disease related proteins are known to be located in the cell\n",
    "- How many reviewed entries (Swiss-Prot) are related to kinase activity?\n",
    "- list all the Homo Sapiens proteins classified with \"cholesterol biosynthetic process\"\n",
    "- list all the Homo Sapiens proteins classified with \"cholesterol biosynthetic process\". Include their names.\n",
    "- list all the Homo Sapiens proteins classified with \"cholesterol biosynthetic process\". Don't include their names.\n",
    "- find all the Homo Sapiens related proteins that have a Gene Ontology (GO) code\n",
    "- look within the taxonomy tree, to see if there are any subclass records under Homo Sapiens. Return the scientific name also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99acee21-8121-458b-832a-856c2e09c674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL query:\n",
      "\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX vg: <http://biohackathon.org/resource/vg#>\n",
      "PREFIX up: <http://purl.uniprot.org/core/>\n",
      "PREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\n",
      "PREFIX uberon: <http://purl.obolibrary.org/obo/uo#>\n",
      "PREFIX taxon: <http://purl.uniprot.org/taxonomy/>\n",
      "PREFIX sp: <http://spinrdf.org/sp#>\n",
      "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
      "PREFIX sio: <http://semanticscience.org/resource/>\n",
      "PREFIX sh: <http://www.w3.org/ns/shacl#>\n",
      "PREFIX schema: <http://schema.org/>\n",
      "PREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\n",
      "PREFIX rh: <http://rdf.rhea-db.org/>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX pubmed: <http://rdf.ncbi.nlm.nih.gov/pubmed/>\n",
      "PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
      "PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
      "PREFIX patent: <http://data.epo.org/linked-data/def/patent/>\n",
      "PREFIX p: <http://www.wikidata.org/prop/>\n",
      "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
      "PREFIX orthodbGroup: <http://purl.orthodb.org/odbgroup/>\n",
      "PREFIX orthodb: <http://purl.orthodb.org/>\n",
      "PREFIX orth: <http://purl.org/net/orth#>\n",
      "PREFIX obo: <http://purl.obolibrary.org/obo/>\n",
      "PREFIX np: <http://nextprot.org/rdf#>\n",
      "PREFIX nextprot: <http://nextprot.org/rdf/entry/>\n",
      "PREFIX mnx: <https://rdf.metanetx.org/schema/>\n",
      "PREFIX mnet: <https://rdf.metanetx.org/mnet/>\n",
      "PREFIX mesh: <http://id.nlm.nih.gov/mesh/>\n",
      "PREFIX lscr: <http://purl.org/lscr#>\n",
      "PREFIX lipidmaps: <https://www.lipidmaps.org/rdf/>\n",
      "PREFIX keywords: <http://purl.uniprot.org/keywords/>\n",
      "PREFIX insdcschema: <http://ddbj.nig.ac.jp/ontologies/nucleotide/>\n",
      "PREFIX insdc: <http://identifiers.org/insdc/>\n",
      "PREFIX identifiers: <http://identifiers.org/>\n",
      "PREFIX glyconnect: <https://purl.org/glyconnect/>\n",
      "PREFIX glycan: <http://purl.jp/bio/12/glyco/glycan#>\n",
      "PREFIX genex: <http://purl.org/genex#>\n",
      "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
      "PREFIX faldo: <http://biohackathon.org/resource/faldo#>\n",
      "PREFIX eunisSpecies: <http://eunis.eea.europa.eu/rdf/species-schema.rdf#>\n",
      "PREFIX ensembltranscript: <http://rdf.ebi.ac.uk/resource/ensembl.transcript/>\n",
      "PREFIX ensemblterms: <http://rdf.ebi.ac.uk/terms/ensembl/>\n",
      "PREFIX ensemblprotein: <http://rdf.ebi.ac.uk/resource/ensembl.protein/>\n",
      "PREFIX ensemblexon: <http://rdf.ebi.ac.uk/resource/ensembl.exon/>\n",
      "PREFIX ensembl: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
      "PREFIX ec: <http://purl.uniprot.org/enzyme/>\n",
      "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
      "PREFIX dc: <http://purl.org/dc/terms/>\n",
      "PREFIX chebislash: <http://purl.obolibrary.org/obo/chebi/>\n",
      "PREFIX chebihash: <http://purl.obolibrary.org/obo/chebi#>\n",
      "PREFIX cco: <http://rdf.ebi.ac.uk/terms/chembl#>\n",
      "PREFIX busco: <http://busco.ezlab.org/schema#>\n",
      "PREFIX bibo: <http://purl.org/ontology/bibo/>\n",
      "PREFIX allie: <http://allie.dbcls.jp/>\n",
      "PREFIX SWISSLIPID: <https://swisslipids.org/rdf/SLM_>\n",
      "PREFIX GO: <http://purl.obolibrary.org/obo/GO_>\n",
      "PREFIX ECO: <http://purl.obolibrary.org/obo/ECO_>\n",
      "PREFIX CHEBI: <http://purl.obolibrary.org/obo/CHEBI_>\n",
      "\n",
      "\n",
      "\n",
      "SELECT ?protein ?location_inside_cell\n",
      "WHERE {\n",
      "    ?protein a up:Protein .\n",
      "    ?protein up:annotation ?subcellAnnotation .\n",
      "    ?subcellAnnotation up:locatedIn/up:cellularComponent ?cellcmpt .\n",
      "    ?cellcmpt skos:prefLabel ?location_inside_cell .\n",
      "    FILTER(REGEX(?location_inside_cell, \"mitochondrion\", \"i\"))\n",
      "}\n",
      "\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_run(\"Show me all proteins that are located in the mitochondrian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e51dead8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL query:\n",
      "\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "PREFIX wikibase: <http://wikiba.se/ontology#>\n",
      "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
      "PREFIX wd: <http://www.wikidata.org/entity/>\n",
      "PREFIX vg: <http://biohackathon.org/resource/vg#>\n",
      "PREFIX up: <http://purl.uniprot.org/core/>\n",
      "PREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\n",
      "PREFIX uberon: <http://purl.obolibrary.org/obo/uo#>\n",
      "PREFIX taxon: <http://purl.uniprot.org/taxonomy/>\n",
      "PREFIX sp: <http://spinrdf.org/sp#>\n",
      "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
      "PREFIX sio: <http://semanticscience.org/resource/>\n",
      "PREFIX sh: <http://www.w3.org/ns/shacl#>\n",
      "PREFIX schema: <http://schema.org/>\n",
      "PREFIX sachem: <http://bioinfo.uochb.cas.cz/rdf/v1.0/sachem#>\n",
      "PREFIX rh: <http://rdf.rhea-db.org/>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX pubmed: <http://rdf.ncbi.nlm.nih.gov/pubmed/>\n",
      "PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
      "PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
      "PREFIX patent: <http://data.epo.org/linked-data/def/patent/>\n",
      "PREFIX p: <http://www.wikidata.org/prop/>\n",
      "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
      "PREFIX orthodbGroup: <http://purl.orthodb.org/odbgroup/>\n",
      "PREFIX orthodb: <http://purl.orthodb.org/>\n",
      "PREFIX orth: <http://purl.org/net/orth#>\n",
      "PREFIX obo: <http://purl.obolibrary.org/obo/>\n",
      "PREFIX np: <http://nextprot.org/rdf#>\n",
      "PREFIX nextprot: <http://nextprot.org/rdf/entry/>\n",
      "PREFIX mnx: <https://rdf.metanetx.org/schema/>\n",
      "PREFIX mnet: <https://rdf.metanetx.org/mnet/>\n",
      "PREFIX mesh: <http://id.nlm.nih.gov/mesh/>\n",
      "PREFIX lscr: <http://purl.org/lscr#>\n",
      "PREFIX lipidmaps: <https://www.lipidmaps.org/rdf/>\n",
      "PREFIX keywords: <http://purl.uniprot.org/keywords/>\n",
      "PREFIX insdcschema: <http://ddbj.nig.ac.jp/ontologies/nucleotide/>\n",
      "PREFIX insdc: <http://identifiers.org/insdc/>\n",
      "PREFIX identifiers: <http://identifiers.org/>\n",
      "PREFIX glyconnect: <https://purl.org/glyconnect/>\n",
      "PREFIX glycan: <http://purl.jp/bio/12/glyco/glycan#>\n",
      "PREFIX genex: <http://purl.org/genex#>\n",
      "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
      "PREFIX faldo: <http://biohackathon.org/resource/faldo#>\n",
      "PREFIX eunisSpecies: <http://eunis.eea.europa.eu/rdf/species-schema.rdf#>\n",
      "PREFIX ensembltranscript: <http://rdf.ebi.ac.uk/resource/ensembl.transcript/>\n",
      "PREFIX ensemblterms: <http://rdf.ebi.ac.uk/terms/ensembl/>\n",
      "PREFIX ensemblprotein: <http://rdf.ebi.ac.uk/resource/ensembl.protein/>\n",
      "PREFIX ensemblexon: <http://rdf.ebi.ac.uk/resource/ensembl.exon/>\n",
      "PREFIX ensembl: <http://rdf.ebi.ac.uk/resource/ensembl/>\n",
      "PREFIX ec: <http://purl.uniprot.org/enzyme/>\n",
      "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
      "PREFIX dc: <http://purl.org/dc/terms/>\n",
      "PREFIX chebislash: <http://purl.obolibrary.org/obo/chebi/>\n",
      "PREFIX chebihash: <http://purl.obolibrary.org/obo/chebi#>\n",
      "PREFIX cco: <http://rdf.ebi.ac.uk/terms/chembl#>\n",
      "PREFIX busco: <http://busco.ezlab.org/schema#>\n",
      "PREFIX bibo: <http://purl.org/ontology/bibo/>\n",
      "PREFIX allie: <http://allie.dbcls.jp/>\n",
      "PREFIX SWISSLIPID: <https://swisslipids.org/rdf/SLM_>\n",
      "PREFIX GO: <http://purl.obolibrary.org/obo/GO_>\n",
      "PREFIX ECO: <http://purl.obolibrary.org/obo/ECO_>\n",
      "PREFIX CHEBI: <http://purl.obolibrary.org/obo/CHEBI_>\n",
      "\n",
      "\n",
      "\n",
      "SELECT (AVG(?linksToPdbPerEntry) AS ?avgLinksToPdbPerEntry)\n",
      "WHERE\n",
      "{\n",
      "    SELECT ?protein (COUNT(DISTINCT ?db) AS ?linksToPdbPerEntry)\n",
      "    WHERE\n",
      "    {\n",
      "        ?protein a up:Protein .\n",
      "        ?protein rdfs:seeAlso ?db .\n",
      "        ?db up:database <http://purl.uniprot.org/database/PDB> .\n",
      "    }\n",
      "    GROUP BY ?protein ORDER BY DESC(?linksToPdbPerEntry)\n",
      "}\n",
      "\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'avgLinksToPdbPerEntry': {'datatype': 'http://www.w3.org/2001/XMLSchema#decimal',\n",
       "   'type': 'literal',\n",
       "   'value': '7.25071137429823886795'}}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_and_run(\"Select the average number of cross-references to the PDB \"\n",
    "                 \"database of UniProt entries that have at least one cross-reference \"\n",
    "                 \"to the PDB database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007c003-86ba-45e2-bae1-03fb141dc667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcf0456",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Install Jinja templating library\n",
    "- Define functions to create prompt and invoke LLM to generate query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q jinja2==3.1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import yaml\n",
    "import json\n",
    "import boto3\n",
    "import utilities as u\n",
    "import jinja2\n",
    "from pathlib import Path\n",
    "from typing import List, Union, Optional\n",
    "from typing import Any as JsonType\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(\n",
    "   retries = {\n",
    "      'max_attempts': 5,\n",
    "      'mode': 'standard'\n",
    "   }\n",
    ")\n",
    "\n",
    "session=boto3.Session()\n",
    "bedrock_runtime = boto3.client(\n",
    "    \"bedrock-runtime\", \n",
    "    region_name=u.AWS_REGION,\n",
    "    config=config\n",
    ")\n",
    "jenv = jinja2.Environment(trim_blocks=True, lstrip_blocks=True)\n",
    "model_id = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "temperature = 0.3\n",
    "resources = Path.cwd() / \"resources\"\n",
    "pfx = (Path.cwd() / \"resources\" / \"prefixes.txt\").read_text()\n",
    "ground_truth = yaml.safe_load((resources / \"ground-truth.yaml\").read_text())\n",
    "tips = yaml.safe_load((resources / \"tips.yaml\").read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb44998",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_json = yaml.safe_load((resources / \"prompt.yaml\").read_text())\n",
    "\n",
    "def apply_jinja(json_blob: JsonType, **kwargs) -> JsonType:\n",
    "    if isinstance(json_blob, str):\n",
    "        return jenv.from_string(json_blob).render(\n",
    "                        question=kwargs[\"question\"],\n",
    "                        tips=kwargs[\"tips\"],\n",
    "                        examples=kwargs[\"examples\"])\n",
    "    elif isinstance(json_blob, list):\n",
    "        return [apply_jinja(x, **kwargs) for x in json_blob]\n",
    "    elif isinstance(json_blob, dict):\n",
    "        return {k: apply_jinja(v, **kwargs) for k, v in json_blob.items()}\n",
    "    else:\n",
    "        return json_blob\n",
    "\n",
    "def generate_prompt(prompt_template_json: JsonType,\n",
    "                    tips: List[str],\n",
    "                    question: str,\n",
    "                    few_shot_examples: List[dict]) -> JsonType:\n",
    "    prompt_json = apply_jinja(prompt_template_json, \n",
    "                               question=question,\n",
    "                               tips=tips,\n",
    "                               examples=few_shot_examples)\n",
    "    return prompt_json\n",
    "    \n",
    "def generate_sparql(prompt_template: JsonType,\n",
    "                    tips: List[str],\n",
    "                    question: str,\n",
    "                    few_shot_examples: List[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Given a natural language question, use the LLM to transform that\n",
    "    into a SPARQL query (using the prompt template) and return the query.\n",
    "    \"\"\"\n",
    "    prompt = generate_prompt(prompt_template, tips, question, few_shot_examples)\n",
    "    sys_prompt=prompt[0]['system']\n",
    "    messages=prompt[1:]\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(\n",
    "            {\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"temperature\": temperature,\n",
    "                \"messages\": messages,\n",
    "                \"system\": sys_prompt\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    result = json.loads(response.get(\"body\").read())\n",
    "    output_list = result.get(\"content\", [])\n",
    "    sparql = \"\".join(output[\"text\"] for output in output_list if output[\"type\"] == \"text\")\n",
    "    \n",
    "    # get inside the <sparql> tag\n",
    "    try:\n",
    "        idx = sparql.index(\"<sparql>\")\n",
    "        sparql = sparql[idx+8:]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        idx = sparql.index(\"</sparql>\")\n",
    "        sparql = sparql[:idx]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    return sparql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5faa6",
   "metadata": {},
   "source": [
    "## Run tests\n",
    "- 4 of the 8 combos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_one_test(index, use_tips, use_few, folder_name):\n",
    "    the_tips = tips if use_tips else []\n",
    "\n",
    "    q=ground_truth[index]\n",
    "    nlq=q['question']\n",
    "    expected_sparql=q['SPARQL']\n",
    "    error_msg=\"\"\n",
    "    gen_sparql=\"\"\n",
    "    res=None\n",
    "\n",
    "    training_examples=[]\n",
    "    if use_few:\n",
    "        training_examples = ground_truth[:index] + ground_truth[index+1:]\n",
    "        assert q[\"SPARQL\"] not in {x[\"SPARQL\"] for x in training_examples}\n",
    "\n",
    "    generated_sparql = generate_sparql(prompt_template_json, the_tips, nlq, training_examples)\n",
    "            \n",
    "    sparql=f\"\"\"\n",
    "        {pfx}\n",
    "\n",
    "        {generated_sparql}\n",
    "\n",
    "        LIMIT 20\n",
    "    \"\"\"\n",
    "            \n",
    "    try:\n",
    "        res=u.execute_sparql(sparql, session) \n",
    "        if 'message' in res:\n",
    "            error_msg=res['message'].replace(\"\\n\", \" \")\n",
    "        if not(folder_name is None):\n",
    "            u.write_sparql_res(folder_name, str(index), nlq, expected_sparql, sparql, res, error_msg)\n",
    "        else:\n",
    "            print(nlq)\n",
    "            print(sparql)\n",
    "            print(res)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {index}\")\n",
    "        print(\"Exception: {}\".format(type(e).__name__))\n",
    "        print(\"Exception message: {}\".format(e))\n",
    "        error_msg=\"Exception message: {}\".format(e).replace(\"\\n\", \" \")\n",
    "        if not(folder_name is None):\n",
    "            u.write_sparql_res(folder_name, str(index), nlq, q['SPARQL'], sparql, [], error_msg)\n",
    "\n",
    "# In our testing our account had a throttle limit on Bedrock runtime model invocation.\n",
    "# Besides using boto3 for retries and backoff, we also introduced a sleep between calls.\n",
    "# Set this to -1 if you do NOT wish to sleep.\n",
    "SLEEP_INTERVAL_SECS=70\n",
    "\n",
    "def run_tests(folder_name, use_tips, use_few):\n",
    "\n",
    "    folder=f\"./{folder_name}\" \n",
    "    if not(os.path.exists(folder) and os.path.isdir(folder)):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    for index, q in enumerate(ground_truth):\n",
    "        if SLEEP_INTERVAL_SECS > 0:\n",
    "            time.sleep(SLEEP_INTERVAL_SECS)\n",
    "        print(f\"{folder_name} {str(index)}\")\n",
    "        run_one_test(index, use_tips, use_few, folder_name)\n",
    "        \n",
    "def run_yourown_query(nlq):\n",
    "    training_examples = ground_truth\n",
    "            \n",
    "    generated_sparql = generate_sparql(prompt_template_json, tips, nlq, training_examples) \n",
    "    sparql=f\"\"\"\n",
    "        {pfx}\n",
    "\n",
    "        {generated_sparql}\n",
    "\n",
    "        LIMIT 20\n",
    "    \"\"\"\n",
    "            \n",
    "    res=u.execute_sparql(sparql, session) \n",
    "    \n",
    "    print(generated_sparql)\n",
    "    print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests(\"implicit_zero\", False, False)\n",
    "\n",
    "run_tests(\"implicit_tips\", True, False)\n",
    "\n",
    "run_tests(\"implicit_few\", False, True)\n",
    "\n",
    "run_tests(\"implicit_few_tips\", True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b49d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.make_report(\"implicit_zero\")\n",
    "u.make_report(\"implicit_tips\")\n",
    "u.make_report(\"implicit_few\")\n",
    "u.make_report(\"implicit_few_tips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1200d5",
   "metadata": {},
   "source": [
    "## One-off queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one_test(5, True, True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c017d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_yourown_query(\"What protein is in frogs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
